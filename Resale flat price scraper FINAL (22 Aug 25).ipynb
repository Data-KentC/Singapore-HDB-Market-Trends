{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1a4b149-5ce5-49ef-8226-abe51942e13a",
   "metadata": {},
   "source": [
    "## Project: Resale Flat Data Consolidation & Cleaning üè°\n",
    "The goal here is to take the data from multiple API endpoints, load it into a single pandas DataFrame, \n",
    "and perform essential data cleaning and transformation steps. We will follow a structured process, using df.head() at each stage to inspect the data and confirm the changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f721a2bf-a32b-4d6e-9380-9e7cdd50d925",
   "metadata": {},
   "source": [
    "Setup and Data Loading\n",
    "This section contains the updated code to fetch all datasets and combine them into one large DataFrame. \n",
    "The fetch_dataset function has been modified to return a DataFrame instead of writing to a CSV file. The main \n",
    "function now collects all these DataFrames and uses pd.concat to merge them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ae712c",
   "metadata": {},
   "source": [
    "## 1. Data Fetching and Combination\n",
    "This cell sets up the environment, defines the dataset sources, and fetches all HDB resale flat datasets from data.gov.sg. It combines them into a single raw DataFrame (`df_raw`) for further cleaning and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31c56d2c-f5d0-4c4e-be5a-a68798073bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching Resale Flat Prices (Based on Approval Date), 1990 - 1999...\n",
      "\n",
      "Fetching Resale Flat Prices (Based on Approval Date), 2000 - Feb 2012...\n",
      "\n",
      "Fetching Resale Flat Prices (Based on Registration Date), From Jan 2015 to Dec 2016...\n",
      "\n",
      "Fetching Resale Flat Prices (Based on Registration Date), From Mar 2012 to Dec 2014...\n",
      "\n",
      "Fetching Resale Flat Prices Based on Registration Date from Jan-2017 onwards...\n",
      "‚úÖ Resale Flat Prices (Based on Registration Date), From Mar 2012 to Dec 2014: 52203 total rows available.\n",
      "‚úÖ Resale Flat Prices (Based on Approval Date), 2000 - Feb 2012: 369651 total rows available.\n",
      "‚úÖ Resale Flat Prices (Based on Approval Date), 1990 - 1999: 287196 total rows available.\n",
      "‚úÖ Resale Flat Prices (Based on Registration Date), From Jan 2015 to Dec 2016: 37153 total rows available.\n",
      "‚úÖ Resale Flat Prices Based on Registration Date from Jan-2017 onwards: 214331 total rows available.\n",
      "\n",
      "--- Initial Raw DataFrame ---\n",
      "     month        town flat_type block       street_name storey_range  \\\n",
      "0  1990-01  ANG MO KIO    1 ROOM   309  ANG MO KIO AVE 1     10 TO 12   \n",
      "1  1990-01  ANG MO KIO    1 ROOM   309  ANG MO KIO AVE 1     04 TO 06   \n",
      "2  1990-01  ANG MO KIO    1 ROOM   309  ANG MO KIO AVE 1     10 TO 12   \n",
      "3  1990-01  ANG MO KIO    1 ROOM   309  ANG MO KIO AVE 1     07 TO 09   \n",
      "4  1990-01  ANG MO KIO    3 ROOM   216  ANG MO KIO AVE 1     04 TO 06   \n",
      "\n",
      "  floor_area_sqm      flat_model lease_commence_date resale_price  \\\n",
      "0             31        IMPROVED                1977         9000   \n",
      "1             31        IMPROVED                1977         6000   \n",
      "2             31        IMPROVED                1977         8000   \n",
      "3             31        IMPROVED                1977         6000   \n",
      "4             73  NEW GENERATION                1976        47200   \n",
      "\n",
      "  remaining_lease  \n",
      "0             NaN  \n",
      "1             NaN  \n",
      "2             NaN  \n",
      "3             NaN  \n",
      "4             NaN  \n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Apply nest_asyncio to allow asyncio.run() in nested environments like Jupyter Notebook\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# --- Configuration ---\n",
    "# Use the full set of datasets to get the complete time range from 1990 onwards\n",
    "datasets = {\n",
    "    \"d_ebc5ab87086db484f88045b47411ebc5\": \"Resale Flat Prices (Based on Approval Date), 1990 - 1999\",\n",
    "    \"d_43f493c6c50d54243cc1eab0df142d6a\": \"Resale Flat Prices (Based on Approval Date), 2000 - Feb 2012\",\n",
    "    \"d_ea9ed51da2787afaf8e51f827c304208\": \"Resale Flat Prices (Based on Registration Date), From Jan 2015 to Dec 2016\",\n",
    "    \"d_2d5ff9ea31397b66239f245f57751537\": \"Resale Flat Prices (Based on Registration Date), From Mar 2012 to Dec 2014\",\n",
    "    \"d_8b84c4ee58e3cfc0ece0d773c8ca6abc\": \"Resale Flat Prices Based on Registration Date from Jan-2017 onwards\",\n",
    "}\n",
    "\n",
    "base_url = \"https://data.gov.sg/api/action/datastore_search?resource_id=\"\n",
    "LIMIT = 10000\n",
    "\n",
    "# --- Asynchronous Fetching Functions (Unchanged) ---\n",
    "async def fetch(session, url):\n",
    "    async with session.get(url) as resp:\n",
    "        return await resp.json()\n",
    "\n",
    "async def fetch_page(session, dataset_id, offset):\n",
    "    url = f\"{base_url}{dataset_id}&limit={LIMIT}&offset={offset}\"\n",
    "    return await fetch(session, url)\n",
    "\n",
    "# --- Main Data Retrieval Logic (Modified) ---\n",
    "async def fetch_dataset(session, dataset_id, name):\n",
    "    print(f\"\\nFetching {name}...\")\n",
    "    first_page = await fetch_page(session, dataset_id, 0)\n",
    "    \n",
    "    if not first_page.get(\"success\"):\n",
    "        print(f\"Failed to fetch data for {name}.\")\n",
    "        return pd.DataFrame() # Return empty DataFrame on failure\n",
    "\n",
    "    total_rows = first_page[\"result\"][\"total\"]\n",
    "    print(f\"‚úÖ {name}: {total_rows} total rows available.\")\n",
    "\n",
    "    total_pages = math.ceil(total_rows / LIMIT)\n",
    "    offsets = [i * LIMIT for i in range(total_pages)]\n",
    "\n",
    "    tasks = [fetch_page(session, dataset_id, offset) for offset in offsets]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "\n",
    "    all_records = []\n",
    "    for data in results:\n",
    "        if data.get(\"success\"):\n",
    "            all_records.extend(data['result']['records'])\n",
    "    \n",
    "    # Return the data as a DataFrame\n",
    "    return pd.DataFrame(all_records)\n",
    "\n",
    "async def main():\n",
    "    \"\"\"Main function to fetch all datasets and combine them.\"\"\"\n",
    "    all_dfs = []\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [fetch_dataset(session, dataset_id, name) for dataset_id, name in datasets.items()]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        for df in results:\n",
    "            if not df.empty:\n",
    "                all_dfs.append(df)\n",
    "            else:\n",
    "                print(\"‚ÄºÔ∏è An entire dataset was not loaded due to a fetch error.\")\n",
    "    \n",
    "    # Combine all DataFrames into one and return\n",
    "    if all_dfs:\n",
    "        return pd.concat(all_dfs, ignore_index=True)\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# Execute the main function to get the combined raw DataFrame\n",
    "df_raw = asyncio.run(main())\n",
    "\n",
    "# Remove '_id' column\n",
    "if '_id' in df_raw.columns:\n",
    "    df_raw = df_raw.drop(columns=['_id'])\n",
    "\n",
    "print(\"\\n--- Initial Raw DataFrame ---\")\n",
    "print(df_raw.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94662b6b-5dda-437a-85c4-a6556a048530",
   "metadata": {},
   "source": [
    "# Print the unique values in the raw month column to inspect for inconsistencies.\n",
    "print(df_raw['month'].unique())\n",
    "\n",
    "num_years = df['year'].unique()\n",
    "print(f'There are {num_years} unique years in the dataframe.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e94f1cb",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning\n",
    "This cell performs essential cleaning and transformation on the raw DataFrame. It standardizes column names, removes duplicates, formats columns, computes derived features (like `remaining_lease_years`), and prepares the data for analytics and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb2f7d6-e4bf-47f8-ae15-92572fb3e964",
   "metadata": {},
   "source": [
    "# --- Data Cleaning ---\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Standardize column names\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Rename _id to id if present\n",
    "if '_id' in df.columns:\n",
    "    df = df.rename(columns={'_id': 'id'})\n",
    "\n",
    "# Remove duplicate rows if id exists\n",
    "if 'id' in df.columns:\n",
    "    df = df.drop_duplicates(subset='id')\n",
    "\n",
    "# Clean string columns\n",
    "for col in ['block', 'street_name', 'town', 'flat_type', 'flat_model']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.strip().str.upper()\n",
    "\n",
    "# Convert resale_price and floor_area_sqm to numeric\n",
    "for col in ['resale_price', 'floor_area_sqm']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Format month column to YYYY-MM and extract year\n",
    "if 'month' in df.columns:\n",
    "    df['month'] = pd.to_datetime(df['month'], format='%Y-%m', errors='coerce').dt.strftime('%Y-%m')\n",
    "    df['year'] = pd.to_datetime(df['month'], format='%Y-%m', errors='coerce').dt.year\n",
    "\n",
    "# Lease commence year to numeric\n",
    "if 'lease_commence_date' in df.columns:\n",
    "    df['lease_commence_date'] = pd.to_numeric(df['lease_commence_date'], errors='coerce')\n",
    "\n",
    "\n",
    "\n",
    "# Parse storey_range into min/max\n",
    "if 'storey_range' in df.columns:\n",
    "    try:\n",
    "        df[['storey_min', 'storey_max']] = df['storey_range'].str.split(' TO ', expand=True).astype(float)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Compute remaining_lease_years as 'YY years MM months' at present date\n",
    "def format_remaining_lease_years(row):\n",
    "    lease_year = row.get('lease_commence_date')\n",
    "    if pd.isna(lease_year) or not lease_year:\n",
    "        return None\n",
    "    try:\n",
    "        lease_year = int(lease_year)\n",
    "    except Exception:\n",
    "        return None\n",
    "    today = datetime.now()\n",
    "    years_elapsed = today.year - lease_year\n",
    "    months_elapsed = today.month - 1\n",
    "    years_left = 99 - years_elapsed\n",
    "    months_left = 0 - months_elapsed\n",
    "    if months_left < 0:\n",
    "        years_left -= 1\n",
    "        months_left += 12\n",
    "    if years_left < 0:\n",
    "        return '0 years 0 months'\n",
    "    return f'{years_left} years {months_left} months'\n",
    "\n",
    "df['remaining_lease_years'] = df.apply(format_remaining_lease_years, axis=1)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Remove the old remaining_lease column if present\n",
    "if 'remaining_lease' in df.columns:\n",
    "    df = df.drop(columns=['remaining_lease'])\n",
    "\n",
    "# Calculate price_per_sqm and round to 2 decimals\n",
    "if 'resale_price' in df.columns and 'floor_area_sqm' in df.columns:\n",
    "    df['price_per_sqm'] = (df['resale_price'] / df['floor_area_sqm']).round(2)\n",
    "\n",
    "\"\"\"\n",
    "# Drop outliers in resale_price\n",
    "if 'resale_price' in df.columns:\n",
    "    df = df[(df['resale_price'] > 50000) & (df['resale_price'] < 2000000)]\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n--- Cleaned DataFrame ---\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0ac934e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cleaned DataFrame ---\n",
      "     month        town flat_type block       street_name storey_range  \\\n",
      "0  1990-01  ANG MO KIO    1 ROOM   309  ANG MO KIO AVE 1     10 TO 12   \n",
      "1  1990-01  ANG MO KIO    1 ROOM   309  ANG MO KIO AVE 1     04 TO 06   \n",
      "2  1990-01  ANG MO KIO    1 ROOM   309  ANG MO KIO AVE 1     10 TO 12   \n",
      "3  1990-01  ANG MO KIO    1 ROOM   309  ANG MO KIO AVE 1     07 TO 09   \n",
      "4  1990-01  ANG MO KIO    3 ROOM   216  ANG MO KIO AVE 1     04 TO 06   \n",
      "\n",
      "   floor_area_sqm      flat_model  lease_commence_date  resale_price  year  \\\n",
      "0            31.0        IMPROVED                 1977        9000.0  1990   \n",
      "1            31.0        IMPROVED                 1977        6000.0  1990   \n",
      "2            31.0        IMPROVED                 1977        8000.0  1990   \n",
      "3            31.0        IMPROVED                 1977        6000.0  1990   \n",
      "4            73.0  NEW GENERATION                 1976       47200.0  1990   \n",
      "\n",
      "  remaining_lease_at_point_of_sale  storey_min  storey_max  price_per_sqm  \n",
      "0                86 years 0 months        10.0        12.0         290.32  \n",
      "1                86 years 0 months         4.0         6.0         193.55  \n",
      "2                86 years 0 months        10.0        12.0         258.06  \n",
      "3                86 years 0 months         7.0         9.0         193.55  \n",
      "4                85 years 0 months         4.0         6.0         646.58  \n"
     ]
    }
   ],
   "source": [
    "# --- Data Cleaning ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Standardize column names\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Clean string columns\n",
    "for col in ['block', 'street_name', 'town', 'flat_type', 'flat_model']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.strip().str.upper()\n",
    "\n",
    "# Convert resale_price and floor_area_sqm to numeric\n",
    "for col in ['resale_price', 'floor_area_sqm']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Format month column to YYYY-MM and extract year\n",
    "if 'month' in df.columns:\n",
    "    df['month'] = pd.to_datetime(df['month'], format='%Y-%m', errors='coerce').dt.strftime('%Y-%m')\n",
    "    df['year'] = pd.to_datetime(df['month'], format='%Y-%m', errors='coerce').dt.year\n",
    "\n",
    "# Lease commence year to numeric\n",
    "if 'lease_commence_date' in df.columns:\n",
    "    df['lease_commence_date'] = pd.to_numeric(df['lease_commence_date'], errors='coerce')\n",
    "\n",
    "# --- Compute remaining lease at point of sale ---\n",
    "def format_remaining_lease_at_sale(row):\n",
    "    lease_year = row.get('lease_commence_date')\n",
    "    sale_month = row.get('month')  # should be YYYY-MM string\n",
    "    if pd.isna(lease_year) or not lease_year:\n",
    "        return None\n",
    "    if pd.isna(sale_month) or not sale_month:\n",
    "        return None\n",
    "    try:\n",
    "        lease_year = int(lease_year)\n",
    "        sale_dt = pd.to_datetime(sale_month, format='%Y-%m', errors='coerce')\n",
    "        if pd.isna(sale_dt):\n",
    "            return None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    # Years and months elapsed since lease commencement\n",
    "    years_elapsed = sale_dt.year - lease_year\n",
    "    months_elapsed = sale_dt.month - 1\n",
    "    years_left = 99 - years_elapsed\n",
    "    months_left = 0 - months_elapsed\n",
    "    if months_left < 0:\n",
    "        years_left -= 1\n",
    "        months_left += 12\n",
    "    if years_left < 0:\n",
    "        return '0 years 0 months'\n",
    "    return f'{years_left} years {months_left} months'\n",
    "\n",
    "df['remaining_lease_at_point_of_sale'] = df.apply(format_remaining_lease_at_sale, axis=1)\n",
    "\n",
    "# Parse storey_range into min/max\n",
    "if 'storey_range' in df.columns:\n",
    "    try:\n",
    "        df[['storey_min', 'storey_max']] = df['storey_range'].str.split(' TO ', expand=True).astype(float)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Remove the old remaining_lease column if present\n",
    "if 'remaining_lease' in df.columns:\n",
    "    df = df.drop(columns=['remaining_lease'])\n",
    "\n",
    "# Calculate price_per_sqm and round to 2 decimals\n",
    "if 'resale_price' in df.columns and 'floor_area_sqm' in df.columns:\n",
    "    df['price_per_sqm'] = (df['resale_price'] / df['floor_area_sqm']).round(2)\n",
    "\n",
    "\"\"\"\n",
    "# Drop outliers in resale_price\n",
    "if 'resale_price' in df.columns:\n",
    "    df = df[(df['resale_price'] > 50000) & (df['resale_price'] < 2000000)]\n",
    "\n",
    "# After all cleaning steps\n",
    "df['id'] = range(1, len(df) + 1)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n--- Cleaned DataFrame ---\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f09e8f8-c243-40c2-afb3-67c00813d322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1990-01' '1990-02' '1990-03' '1990-04' '1990-05' '1990-06' '1990-07'\n",
      " '1990-08' '1990-09' '1990-10' '1990-11' '1990-12' '1991-01' '1991-02'\n",
      " '1991-03' '1991-04' '1991-05' '1991-06' '1991-07' '1991-08' '1991-09'\n",
      " '1991-10' '1991-11' '1991-12' '1992-01' '1992-02' '1992-03' '1992-04'\n",
      " '1992-05' '1992-06' '1992-07' '1992-08' '1992-09' '1992-10' '1992-11'\n",
      " '1992-12' '1993-01' '1993-02' '1993-03' '1993-04' '1993-05' '1993-06'\n",
      " '1993-07' '1993-08' '1993-09' '1993-10' '1993-11' '1993-12' '1994-01'\n",
      " '1994-02' '1994-03' '1994-04' '1994-05' '1994-06' '1994-07' '1994-08'\n",
      " '1994-09' '1994-10' '1994-11' '1994-12' '1995-01' '1995-02' '1995-03'\n",
      " '1995-04' '1995-05' '1995-06' '1995-07' '1995-08' '1995-09' '1995-10'\n",
      " '1995-11' '1995-12' '1996-01' '1996-02' '1996-03' '1996-04' '1996-05'\n",
      " '1996-06' '1996-07' '1996-08' '1996-09' '1996-10' '1996-11' '1996-12'\n",
      " '1997-01' '1997-02' '1997-03' '1997-04' '1997-05' '1997-06' '1997-07'\n",
      " '1997-08' '1997-09' '1997-10' '1997-11' '1997-12' '1998-01' '1998-02'\n",
      " '1998-03' '1998-04' '1998-05' '1998-06' '1998-07' '1998-08' '1998-09'\n",
      " '1998-10' '1998-11' '1998-12' '1999-01' '1999-02' '1999-03' '1999-04'\n",
      " '1999-05' '1999-06' '1999-07' '1999-08' '1999-09' '1999-10' '1999-11'\n",
      " '1999-12' '2000-01' '2000-02' '2000-03' '2000-04' '2000-05' '2000-06'\n",
      " '2000-07' '2000-08' '2000-09' '2000-10' '2000-11' '2000-12' '2001-01'\n",
      " '2001-02' '2001-03' '2001-04' '2001-05' '2001-06' '2001-07' '2001-08'\n",
      " '2001-09' '2001-10' '2001-11' '2001-12' '2002-01' '2002-02' '2002-03'\n",
      " '2002-04' '2002-05' '2002-06' '2002-07' '2002-08' '2002-09' '2002-10'\n",
      " '2002-11' '2002-12' '2003-01' '2003-02' '2003-03' '2003-04' '2003-05'\n",
      " '2003-06' '2003-07' '2003-08' '2003-09' '2003-10' '2003-11' '2003-12'\n",
      " '2004-01' '2004-02' '2004-03' '2004-04' '2004-05' '2004-06' '2004-07'\n",
      " '2004-08' '2004-09' '2004-10' '2004-11' '2004-12' '2005-01' '2005-02'\n",
      " '2005-03' '2005-04' '2005-05' '2005-06' '2005-07' '2005-08' '2005-09'\n",
      " '2005-10' '2005-11' '2005-12' '2006-01' '2006-02' '2006-03' '2006-04'\n",
      " '2006-05' '2006-06' '2006-07' '2006-08' '2006-09' '2006-10' '2006-11'\n",
      " '2006-12' '2007-01' '2007-02' '2007-03' '2007-04' '2007-05' '2007-06'\n",
      " '2007-07' '2007-08' '2007-09' '2007-10' '2007-11' '2007-12' '2008-01'\n",
      " '2008-02' '2008-03' '2008-04' '2008-05' '2008-06' '2008-07' '2008-08'\n",
      " '2008-09' '2008-10' '2008-11' '2008-12' '2009-01' '2009-02' '2009-03'\n",
      " '2009-04' '2009-05' '2009-06' '2009-07' '2009-08' '2009-09' '2009-10'\n",
      " '2009-11' '2009-12' '2010-01' '2010-02' '2010-03' '2010-04' '2010-05'\n",
      " '2010-06' '2010-07' '2010-08' '2010-09' '2010-10' '2010-11' '2010-12'\n",
      " '2011-01' '2011-02' '2011-03' '2011-04' '2011-05' '2011-06' '2011-07'\n",
      " '2011-08' '2011-09' '2011-10' '2011-11' '2011-12' '2012-01' '2012-02'\n",
      " '2015-01' '2015-02' '2015-03' '2015-04' '2015-05' '2015-06' '2015-07'\n",
      " '2015-08' '2015-09' '2015-10' '2015-11' '2015-12' '2016-01' '2016-02'\n",
      " '2016-03' '2016-04' '2016-05' '2016-06' '2016-07' '2016-08' '2016-09'\n",
      " '2016-10' '2016-11' '2016-12' '2012-03' '2012-04' '2012-05' '2012-06'\n",
      " '2012-07' '2012-08' '2012-09' '2012-10' '2012-11' '2012-12' '2013-01'\n",
      " '2013-02' '2013-03' '2013-04' '2013-05' '2013-06' '2013-07' '2013-08'\n",
      " '2013-09' '2013-10' '2013-11' '2013-12' '2014-01' '2014-02' '2014-03'\n",
      " '2014-04' '2014-05' '2014-06' '2014-07' '2014-08' '2014-09' '2014-10'\n",
      " '2014-11' '2014-12' '2017-01' '2017-02' '2017-03' '2017-04' '2017-05'\n",
      " '2017-06' '2017-07' '2017-08' '2017-09' '2017-10' '2017-11' '2017-12'\n",
      " '2018-01' '2018-02' '2018-03' '2018-04' '2018-05' '2018-06' '2018-07'\n",
      " '2018-08' '2018-09' '2018-10' '2018-11' '2018-12' '2019-01' '2019-02'\n",
      " '2019-03' '2019-04' '2019-05' '2019-06' '2019-07' '2019-08' '2019-09'\n",
      " '2019-10' '2019-11' '2019-12' '2020-01' '2020-02' '2020-03' '2020-04'\n",
      " '2020-05' '2020-06' '2020-07' '2020-08' '2020-09' '2020-10' '2020-11'\n",
      " '2020-12' '2021-01' '2021-02' '2021-03' '2021-04' '2021-05' '2021-06'\n",
      " '2021-07' '2021-08' '2021-09' '2021-10' '2021-11' '2021-12' '2022-01'\n",
      " '2022-02' '2022-03' '2022-04' '2022-05' '2022-06' '2022-07' '2022-08'\n",
      " '2022-09' '2022-10' '2022-11' '2022-12' '2023-01' '2023-02' '2023-03'\n",
      " '2023-04' '2023-05' '2023-06' '2023-07' '2023-08' '2023-09' '2023-10'\n",
      " '2023-11' '2023-12' '2024-02' '2024-04' '2024-06' '2024-09' '2024-11'\n",
      " '2024-12' '2024-01' '2024-03' '2024-07' '2024-05' '2024-08' '2024-10'\n",
      " '2025-05' '2025-08' '2025-01' '2025-03' '2025-02' '2025-06' '2025-07'\n",
      " '2025-04']\n",
      "There are [1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003\n",
      " 2004 2005 2006 2007 2008 2009 2010 2011 2012 2015 2016 2013 2014 2017\n",
      " 2018 2019 2020 2021 2022 2023 2024 2025] unique years in the dataframe.\n"
     ]
    }
   ],
   "source": [
    "# Print the unique values in the raw month column to inspect for inconsistencies.\n",
    "print(df_raw['month'].unique())\n",
    "num_years = df['year'].unique()\n",
    "print(f'There are {num_years} unique years in the dataframe.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe70c311",
   "metadata": {},
   "source": [
    "## 3. Star Schema Construction\n",
    "This cell builds a star schema from the cleaned DataFrame. It creates dimension tables (flat, location, storey, time) and a fact table for resale transactions, enabling efficient analytics and reporting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9c79d7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "476a861a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Flat Dimension:\n",
      "    flat_id flat_type      flat_model  floor_area_sqm  lease_commence_date\n",
      "0        1    1 ROOM        IMPROVED            31.0                 1977\n",
      "1        2    3 ROOM  NEW GENERATION            73.0                 1976\n",
      "2        3    3 ROOM  NEW GENERATION            67.0                 1977\n",
      "3        4    3 ROOM  NEW GENERATION            82.0                 1976\n",
      "4        5    3 ROOM  NEW GENERATION            67.0                 1976\n",
      "\n",
      "Location Dimension:\n",
      "    location_id        town       street_name block\n",
      "0            1  ANG MO KIO  ANG MO KIO AVE 1   309\n",
      "1            2  ANG MO KIO  ANG MO KIO AVE 1   216\n",
      "2            3  ANG MO KIO  ANG MO KIO AVE 3   211\n",
      "3            4  ANG MO KIO  ANG MO KIO AVE 3   202\n",
      "4            5  ANG MO KIO  ANG MO KIO AVE 3   235\n",
      "\n",
      "Storey Dimension:\n",
      "    storey_id storey_range  storey_min  storey_max\n",
      "0          1     10 TO 12        10.0        12.0\n",
      "1          2     04 TO 06         4.0         6.0\n",
      "2          3     07 TO 09         7.0         9.0\n",
      "3          4     01 TO 03         1.0         3.0\n",
      "4          5     13 TO 15        13.0        15.0\n",
      "\n",
      "Time Dimension:\n",
      "    time_id  year    month\n",
      "0        1  1990  1990-01\n",
      "1        2  1990  1990-02\n",
      "2        3  1990  1990-03\n",
      "3        4  1990  1990-04\n",
      "4        5  1990  1990-05\n",
      "\n",
      "Fact Table:\n",
      "    flat_id  location_id  storey_id  time_id  resale_price  price_per_sqm  \\\n",
      "0        1            1          1        1        9000.0         290.32   \n",
      "1        1            1          2        1        6000.0         193.55   \n",
      "2        1            1          1        1        8000.0         258.06   \n",
      "3        1            1          3        1        6000.0         193.55   \n",
      "4        2            2          2        1       47200.0         646.58   \n",
      "\n",
      "  remaining_lease_at_point_of_sale  \n",
      "0                86 years 0 months  \n",
      "1                86 years 0 months  \n",
      "2                86 years 0 months  \n",
      "3                86 years 0 months  \n",
      "4                85 years 0 months  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Build Star Schema from Cleaned DataFrame ---\n",
    "\n",
    "# 1. Flat Dimension\n",
    "flat_dim = df[['flat_type', 'flat_model', 'floor_area_sqm', 'lease_commence_date']].drop_duplicates().reset_index(drop=True)\n",
    "flat_dim['flat_id'] = flat_dim.index + 1  # synthetic key\n",
    "flat_dim = flat_dim[['flat_id', 'flat_type', 'flat_model', 'floor_area_sqm', 'lease_commence_date']]\n",
    "\n",
    "# 2. Location Dimension\n",
    "location_dim = df[['town', 'street_name', 'block']].drop_duplicates().reset_index(drop=True)\n",
    "location_dim['location_id'] = location_dim.index + 1\n",
    "location_dim = location_dim[['location_id', 'town', 'street_name', 'block']]\n",
    "\n",
    "# 3. Storey Dimension\n",
    "storey_dim = df[['storey_range', 'storey_min', 'storey_max']].drop_duplicates().reset_index(drop=True)\n",
    "storey_dim['storey_id'] = storey_dim.index + 1\n",
    "storey_dim = storey_dim[['storey_id', 'storey_range', 'storey_min', 'storey_max']]\n",
    "\n",
    "# 4. Time Dimension\n",
    "time_dim = df[['year', 'month']].drop_duplicates().reset_index(drop=True)\n",
    "time_dim['time_id'] = time_dim.index + 1\n",
    "time_dim = time_dim[['time_id', 'year', 'month']]\n",
    "\n",
    "# 5. Fact Table (Resale Transactions)\n",
    "fact_table = df.merge(flat_dim, on=['flat_type', 'flat_model', 'floor_area_sqm', 'lease_commence_date'], how='left') \\\n",
    "               .merge(location_dim, on=['town', 'street_name', 'block'], how='left') \\\n",
    "               .merge(storey_dim, on=['storey_range', 'storey_min', 'storey_max'], how='left') \\\n",
    "               .merge(time_dim, on=['year', 'month'], how='left')\n",
    "\n",
    "fact_table = fact_table[['flat_id', 'location_id', 'storey_id', 'time_id',\n",
    "                         'resale_price', 'price_per_sqm', 'remaining_lease_at_point_of_sale']]\n",
    "\n",
    "\n",
    "# --- Final Outputs ---\n",
    "print(\"\\nFlat Dimension:\\n\", flat_dim.head())\n",
    "print(\"\\nLocation Dimension:\\n\", location_dim.head())\n",
    "print(\"\\nStorey Dimension:\\n\", storey_dim.head())\n",
    "print(\"\\nTime Dimension:\\n\", time_dim.head())\n",
    "print(\"\\nFact Table:\\n\", fact_table.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fc6c272-bdca-499b-9800-efd05bf7994d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are [1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003\n",
      " 2004 2005 2006 2007 2008 2009 2010 2011 2012 2015 2016 2013 2014 2017\n",
      " 2018 2019 2020 2021 2022 2023 2024 2025] unique years in the dataframe.\n"
     ]
    }
   ],
   "source": [
    "num_years = df['year'].unique()\n",
    "print(f'There are {num_years} unique years in the dataframe.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2403e4e0",
   "metadata": {},
   "source": [
    "## 4. Referential Integrity Check\n",
    "This cell verifies that all fact table rows are correctly linked to their dimension tables and that transaction IDs are unique and sequential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "165eb45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Referential Integrity Check ---\n",
      "Missing flat_id: 0\n",
      "Missing location_id: 0\n",
      "Missing storey_id: 0\n",
      "Missing time_id: 0\n",
      "‚úÖ All fact rows are linked correctly, transaction_id is unique and sequential.\n"
     ]
    }
   ],
   "source": [
    "# --- Referential Integrity Check ---\n",
    "missing_flat = fact_table['flat_id'].isna().sum()\n",
    "missing_loc = fact_table['location_id'].isna().sum()\n",
    "missing_storey = fact_table['storey_id'].isna().sum()\n",
    "missing_time = fact_table['time_id'].isna().sum()\n",
    "\n",
    "print(\"\\n--- Referential Integrity Check ---\")\n",
    "print(f\"Missing flat_id: {missing_flat}\")\n",
    "print(f\"Missing location_id: {missing_loc}\")\n",
    "print(f\"Missing storey_id: {missing_storey}\")\n",
    "print(f\"Missing time_id: {missing_time}\")\n",
    "\n",
    "if all(x == 0 for x in [missing_flat, missing_loc, missing_storey, missing_time]):\n",
    "    print(\"‚úÖ All fact rows are linked correctly, transaction_id is unique and sequential.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Warning: Issues exist in fact table or dimension links.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c8235e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9ba8a43",
   "metadata": {},
   "source": [
    "## 5. Save Outputs\n",
    "This cell saves all dimension tables, the fact table, and the cleaned DataFrame to CSV files in the `star_schema_outputs` directory for further use or sharing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29f34950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ All tables saved to: star_schema_outputs\n"
     ]
    }
   ],
   "source": [
    "import os  # <--- make sure this is at the top of your notebook/script\n",
    "\n",
    "# --- Save Outputs ---\n",
    "output_dir = \"star_schema_outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "flat_dim.to_csv(os.path.join(output_dir, \"flat_dim.csv\"), index=False)\n",
    "location_dim.to_csv(os.path.join(output_dir, \"location_dim.csv\"), index=False)\n",
    "storey_dim.to_csv(os.path.join(output_dir, \"storey_dim.csv\"), index=False)\n",
    "time_dim.to_csv(os.path.join(output_dir, \"time_dim.csv\"), index=False)\n",
    "fact_table.to_csv(os.path.join(output_dir, \"resale_transactions_fact.csv\"), index=False)\n",
    "df.to_csv(os.path.join(output_dir, \"cleaned_dataframe.csv\"), index=False)\n",
    "\n",
    "print(\"\\n‚úÖ All tables saved to:\", output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274da0c6-b2dc-4dc8-bc72-6dc8d0f921e5",
   "metadata": {},
   "source": [
    "## 6. CREATES TABLES IN POSTGRES\n",
    "User to update PGadmin username and password in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4a2f251-8751-4d82-b523-3ae251844623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in c:\\users\\chanc\\anaconda3\\lib\\site-packages (2.9.10)\n",
      "Database 'resale_flat_sg2' created.\n",
      "‚úÖ All tables loaded to PostgreSQL database resale_flat_sg.\n"
     ]
    }
   ],
   "source": [
    "# --- Load All DataFrames to PostgreSQL ---\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy\n",
    "!pip install psycopg2-binary\n",
    " \n",
    "# --- User must set these values for their PostgreSQL instance ---\n",
    "PG_USER = 'postgres'      # e.g. 'postgres'\n",
    "PG_PASSWORD = 'Anypass78'  # e.g. 'mypassword'\n",
    "PG_HOST = 'localhost'          # e.g. 'localhost' or IP address\n",
    "PG_PORT = '5432'               # default PostgreSQL port\n",
    "db_name = 'resale_flat_sg2'\n",
    " \n",
    "# --- Create the database if it doesn't exist ---\n",
    "default_engine = create_engine(f'postgresql+psycopg2://{PG_USER}:{PG_PASSWORD}@{PG_HOST}:{PG_PORT}/postgres')\n",
    "with default_engine.connect() as conn:\n",
    "    conn.execute(sqlalchemy.text(f'COMMIT'))\n",
    "    # Check if database exists before trying to create it\n",
    "    result = conn.execute(sqlalchemy.text(f\"SELECT 1 FROM pg_database WHERE datname = '{db_name}'\"))\n",
    "    exists = result.fetchone()\n",
    "    if not exists:\n",
    "        conn.execute(sqlalchemy.text(f'CREATE DATABASE {db_name}'))\n",
    "        print(f\"Database '{db_name}' created.\")\n",
    "    else:\n",
    "        print(f\"Database '{db_name}' already exists. Skipping creation.\")\n",
    " \n",
    "# --- Connect to the new database ---\n",
    "engine = create_engine(f'postgresql+psycopg2://{PG_USER}:{PG_PASSWORD}@{PG_HOST}:{PG_PORT}/{db_name}')\n",
    " \n",
    "# --- Write all tables ---\n",
    "flat_dim.to_sql('flat_dim', engine, if_exists='replace', index=False)\n",
    "location_dim.to_sql('location_dim', engine, if_exists='replace', index=False)\n",
    "storey_dim.to_sql('storey_dim', engine, if_exists='replace', index=False)\n",
    "time_dim.to_sql('time_dim', engine, if_exists='replace', index=False)\n",
    "fact_table.to_sql('resale_transactions_fact', engine, if_exists='replace', index=False)\n",
    " \n",
    "print('‚úÖ All tables loaded to PostgreSQL database resale_flat_sg.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbace7e-c7a3-4cfb-b284-788bb6722468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
